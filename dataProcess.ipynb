{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa7a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy.core.numeric import ones_like\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# s=str(input(\"Enter the DNA sequence:\"))\n",
    "# k=int(input(\"k to from k mers:\"))\n",
    "\n",
    "class DeBruijnGraph:\n",
    "    def chop(self,st,k):\n",
    "        a=np.empty([0])\n",
    "        b=np.empty([0])\n",
    "        c=np.empty([0])\n",
    "        for i in range(0, len(st)-(k-1)):\n",
    "            a=np.append(a,[st[i:i+k]],axis=0)\n",
    "            b=np.append(b,[st[i:i+k-1]],axis=0)\n",
    "            c=np.append(c,st[i+1:i+k])\n",
    "        return a,b,c\n",
    "\n",
    "    def generate(self,st,k):\n",
    "        if k<=1 :\n",
    "            print(\"invalid value of k returning empty graph\")\n",
    "            return\n",
    "        if len(st)<k:\n",
    "            print(\"insufficient size of string input returning empty graph\")\n",
    "            return\n",
    "        a,b,c= self.chop(st,k)\n",
    "        hash={b[0]:0}\n",
    "        j=1\n",
    "        for i in range (0,a.shape[0]):\n",
    "            if c[i] in hash :\n",
    "               self.edge_index=np.append(self.edge_index,[[hash[b[i]]],[hash[c[i]]]],axis=1)\n",
    "            else:\n",
    "                hash[c[i]]=j\n",
    "                j=j+1\n",
    "                self.edge_index=np.append(self.edge_index,[[hash[b[i]]],[hash[c[i]]]],axis=1) \n",
    "        for h in hash:\n",
    "            self.x=np.append(self.x,[[h]],axis=0)\n",
    "\n",
    "    def reverse(self): #gives back the DNA sequence from the graph\n",
    "        #print(self.edge_index.shape)\n",
    "        if self.edge_index.shape[1]==0 or self.x.shape[0]==0:\n",
    "            return ''\n",
    "        a=self.x[self.edge_index[0][0]][0]\n",
    "        b=self.x[self.edge_index[1][0]][0]\n",
    "        kmer=a[0:len(a)-1]+b\n",
    "        st=kmer\n",
    "        for i in range (1,self.edge_index.shape[1]):\n",
    "            a=self.x[self.edge_index[0][i]][0]\n",
    "            b=self.x[self.edge_index[1][i]][0]\n",
    "            kmer=a[0:len(a)-1]+b\n",
    "            st=st+kmer[len(kmer)-1]\n",
    "        return st\n",
    "\n",
    "    def one_hot_encode(self, seq):\n",
    "    \tmapping = dict(zip(\"ACGT\", range(4)))    \n",
    "    \tseq2 = [mapping[i] for i in seq]\n",
    "    \treturn np.eye(4)[seq2]    \n",
    "    \n",
    "    def __init__(self,st,k):\n",
    "        x=np.empty([0,1])\n",
    "        edge_index=np.empty([2,0],dtype=int)\n",
    "        self.x=x\n",
    "        self.edge_index=edge_index\n",
    "        self.generate(st,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799c63c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:56<00:00, 176.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoints: 10000\n",
      "x_shape: torch.Size([16, 8])\n",
      "edge_index_shape: torch.Size([2, 198])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "kmer, DATALIST = 3, []\n",
    "for i in tqdm(range(10000)):\n",
    "    onehot_x = []\n",
    "    # Generate random DNA sequences\n",
    "    s =''.join(random.choices(['A','T','G','C'], k=200))\n",
    "    d=DeBruijnGraph(s,kmer)    \n",
    "    for node in d.x.flatten():\n",
    "        one_hot_ = d.one_hot_encode(node).flatten()\n",
    "        onehot_x.append(one_hot_.tolist())\n",
    "\n",
    "    # Arrays to pytorch tensors\n",
    "    onehot_x_tensor = torch.tensor(np.array(onehot_x), dtype=torch.float)\n",
    "    onehot_edge_index_tensor = torch.tensor(d.edge_index, dtype=torch.long)\n",
    "    \n",
    "    # generate random label\n",
    "    y_tensor = torch.tensor(random.choice([0, 1]))\n",
    "\n",
    "    # Add tensors to torch_geometric data object\n",
    "    data = Data(x=onehot_x_tensor, edge_index=onehot_edge_index_tensor, y=y_tensor)\n",
    "\n",
    "    DATALIST.append(data)\n",
    "\n",
    "print('Datapoints:', len(DATALIST))\n",
    "\n",
    "print('x_shape:', DATALIST[0].x.shape)\n",
    "print('edge_index_shape:', DATALIST[1].edge_index.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46be4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(edge_index=[2, 198], x=[16, 8], y=0)\n",
      "=============================================================\n",
      "Number of nodes: 16\n",
      "Number of edges: 198\n",
      "Average node degree: 12.38\n",
      "Contains self-loops: True\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "data = DATALIST[1]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "# pytorch dataloader usage\n",
    "loader = DataLoader(DATALIST, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5be285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graph: 7500\n",
      "Number of testing graph: 2500\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "torch.manual_seed(11)\n",
    "# dataset = random.shuffle(DATALIST)\n",
    "\n",
    "train_dataset = DATALIST[:7500]\n",
    "test_dataset = DATALIST[7500:]\n",
    "\n",
    "print('Number of training graph:', len(train_dataset))\n",
    "print('Number of testing graph:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21e681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 2:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 3:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 4:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 5:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 6:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 7:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 8:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 9:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 10:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 11:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 12:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 13:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 14:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 15:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 16:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 17:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 18:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 19:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 20:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 21:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 22:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 23:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 24:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 25:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 26:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 27:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 28:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 29:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 30:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 31:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 32:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 33:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 34:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 35:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 36:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 37:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 38:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 39:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 40:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 41:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 42:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 43:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 44:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 45:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 46:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 47:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 48:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 49:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 50:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 51:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 52:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 53:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 54:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 55:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 56:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 57:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 58:\n",
      "=====\n",
      "Number of graphs in current batch: 128\n",
      "Batch(batch=[2048], edge_index=[2, 25344], ptr=[129], x=[2048, 8], y=[128])\n",
      "\n",
      "Step 59:\n",
      "=====\n",
      "Number of graphs in current batch: 76\n",
      "Batch(batch=[1216], edge_index=[2, 15048], ptr=[77], x=[1216, 8], y=[76])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step+1}:')\n",
    "    print('=====')\n",
    "    print(f'Number of graphs in current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2176bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(8, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (conv3): GCNConv(256, 256)\n",
      "  (lin): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(5)\n",
    "        self.conv1 = GCNConv(8, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Get node embeeding\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        # Readout alayer\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Out layer\n",
    "        # x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = GCN(hidden_channels=256)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35cdfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 25344])\n",
      "torch.Size([2048, 8])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data.edge_index.shape)\n",
    "    print(data.x.shape)\n",
    "    print(data.batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740832c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Current cuda device ID: 1\n",
      "Current cuda device name: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.set_device(1)\n",
    "print('Current cuda device ID:',torch.cuda.current_device())\n",
    "print('Current cuda device name:', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8195ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test\n",
    "model = GCN(hidden_channels=256)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def to_device(data, device):\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        a = to_device(data.x, device)\n",
    "        b = to_device(data.edge_index, device)\n",
    "        c = to_device(data.batch, device)\n",
    "        d = to_device(data.y, device)\n",
    "        \n",
    "        out = model(a, b, c)\n",
    "        loss = loss_func(out, d)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        a = to_device(data.x, device)\n",
    "        b = to_device(data.edge_index, device)\n",
    "        c = to_device(data.batch, device)\n",
    "        d = to_device(data.y, device)\n",
    "        \n",
    "        out = model(a, b, c)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred==d).sum())\n",
    "    return correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ba7ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:001, Train acc: 0.4993, Test acc: 0.5020\n",
      "Epoch:002, Train acc: 0.5007, Test acc: 0.4980\n",
      "Epoch:003, Train acc: 0.4993, Test acc: 0.5020\n",
      "Epoch:004, Train acc: 0.5007, Test acc: 0.4980\n",
      "Epoch:005, Train acc: 0.4993, Test acc: 0.5020\n",
      "Epoch:006, Train acc: 0.5007, Test acc: 0.4980\n",
      "Epoch:007, Train acc: 0.4993, Test acc: 0.5020\n",
      "Epoch:008, Train acc: 0.5007, Test acc: 0.4980\n",
      "Epoch:009, Train acc: 0.4993, Test acc: 0.5020\n"
     ]
    }
   ],
   "source": [
    "train_, test_ = [], []\n",
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    \n",
    "    train_.append(train_acc)\n",
    "    test_.append(test_acc)\n",
    "    \n",
    "    print(f'Epoch:{epoch:03d}, Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec50786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "541ddb3d",
   "metadata": {},
   "source": [
    "## loader.dataset[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
